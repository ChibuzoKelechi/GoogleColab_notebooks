{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCoCOtcSvDnXbeY9qDPqdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChibuzoKelechi/GoogleColab_notebooks/blob/main/sentiment_classifier_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "b32llkRlYNuv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras as tfkeras\n",
        "from keras import layers, losses\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzKpeGqb5hj_",
        "outputId": "0e63d6cd-8d22-49ec-b1c7-2f0465490dc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data = '/content/drive/MyDrive/Datasets/Twitter_reddit SA data/Reddit_Data.csv'\n",
        "# reddit_data = 'https://drive.google.com/file/d/1ludyoukT1kH5YkEiIkuA5WmCjsMig4T4/view?usp=drive_link'\n",
        "\n",
        "dataset = pd.read_csv(reddit_data)\n",
        "\n",
        "comments = dataset['clean_comment']\n",
        "categories = dataset['category']\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for sentence in comments:\n",
        "  # sentences.append(str(dataset['clean_comment'].tolist()))\n",
        "  sentences.append(str(sentence))\n",
        "\n",
        "for category in categories:\n",
        "  labels.append(category)\n",
        "\n",
        "train_size = 28000\n",
        "vocab_size = 48244\n",
        "embedding_dim = 50\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "pad_type='post'\n",
        "training_size = 20000\n",
        "\n",
        "train_text = sentences[0:train_size]\n",
        "test_text = sentences[train_size:]\n",
        "\n",
        "train_labels = labels[0:train_size]\n",
        "test_labels = labels[train_size:]"
      ],
      "metadata": {
        "id": "_gmgNoq2Z7Bd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "train_sequence = tokenizer.texts_to_sequences(train_text)\n",
        "train_padded = pad_sequences(train_sequence, padding='post', maxlen=100, truncating=trunc_type)\n",
        "\n",
        "test_sequence = tokenizer.texts_to_sequences(test_text)\n",
        "test_padded = pad_sequences(test_sequence, padding='post', maxlen=100, truncating=trunc_type)\n",
        "\n",
        "train_padded = np.array(train_padded)\n",
        "train_labels = np.array(train_labels)\n",
        "test_padded = np.array(test_padded)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "train_labels = train_labels.reshape(-1, 1)\n",
        "test_labels = test_labels.reshape(-1, 1)\n",
        "\n",
        "test_labels = test_labels[:len(test_padded)]\n",
        "\n",
        "dataset_shape = dataset.shape\n",
        "\n",
        "train_labels = to_categorical(train_labels, num_classes=3)\n",
        "test_labels = to_categorical(test_labels, num_classes=3)\n"
      ],
      "metadata": {
        "id": "lZmiRPfXxcTr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tfkeras.callbacks.EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "_ay4dSgXZoCQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_model = tfkeras.Sequential([\n",
        "    layers.Embedding(vocab_size, embedding_dim, input_length=100),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "text_model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "OZtyX5kbJ_QK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = text_model.fit(train_padded, train_labels,\n",
        "    epochs=30,\n",
        "    validation_data=(test_padded, test_labels),\n",
        "    verbose=1\n",
        "    # callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPiZhJq3HCRT",
        "outputId": "f91c87d7-684b-405e-dcb8-d1712e334d02"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "875/875 [==============================] - 31s 34ms/step - loss: 0.8026 - accuracy: 0.6373 - val_loss: 0.6202 - val_accuracy: 0.7784\n",
            "Epoch 2/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.4285 - accuracy: 0.8416 - val_loss: 0.4222 - val_accuracy: 0.8544\n",
            "Epoch 3/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.2838 - accuracy: 0.8998 - val_loss: 0.5175 - val_accuracy: 0.8086\n",
            "Epoch 4/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.2334 - accuracy: 0.9180 - val_loss: 0.5068 - val_accuracy: 0.8300\n",
            "Epoch 5/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.1876 - accuracy: 0.9332 - val_loss: 0.6047 - val_accuracy: 0.8267\n",
            "Epoch 6/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.1682 - accuracy: 0.9406 - val_loss: 0.5008 - val_accuracy: 0.8531\n",
            "Epoch 7/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.1590 - accuracy: 0.9444 - val_loss: 0.5205 - val_accuracy: 0.8576\n",
            "Epoch 8/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.1452 - accuracy: 0.9491 - val_loss: 0.6689 - val_accuracy: 0.8055\n",
            "Epoch 9/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.1341 - accuracy: 0.9520 - val_loss: 0.6741 - val_accuracy: 0.8298\n",
            "Epoch 10/30\n",
            "875/875 [==============================] - 29s 34ms/step - loss: 0.1224 - accuracy: 0.9566 - val_loss: 0.5912 - val_accuracy: 0.8451\n",
            "Epoch 11/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.1216 - accuracy: 0.9578 - val_loss: 0.6390 - val_accuracy: 0.8416\n",
            "Epoch 12/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.1167 - accuracy: 0.9594 - val_loss: 0.7678 - val_accuracy: 0.8242\n",
            "Epoch 13/30\n",
            "875/875 [==============================] - 28s 33ms/step - loss: 0.1117 - accuracy: 0.9616 - val_loss: 0.6612 - val_accuracy: 0.8416\n",
            "Epoch 14/30\n",
            "875/875 [==============================] - 29s 34ms/step - loss: 0.1000 - accuracy: 0.9649 - val_loss: 0.6341 - val_accuracy: 0.8497\n",
            "Epoch 15/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.1012 - accuracy: 0.9647 - val_loss: 0.7214 - val_accuracy: 0.8379\n",
            "Epoch 16/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0898 - accuracy: 0.9697 - val_loss: 0.6832 - val_accuracy: 0.8437\n",
            "Epoch 17/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0925 - accuracy: 0.9676 - val_loss: 0.7662 - val_accuracy: 0.8204\n",
            "Epoch 18/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0852 - accuracy: 0.9704 - val_loss: 0.7087 - val_accuracy: 0.8494\n",
            "Epoch 19/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.0807 - accuracy: 0.9719 - val_loss: 0.7968 - val_accuracy: 0.8322\n",
            "Epoch 20/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0829 - accuracy: 0.9725 - val_loss: 1.0415 - val_accuracy: 0.7972\n",
            "Epoch 21/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0787 - accuracy: 0.9725 - val_loss: 0.8840 - val_accuracy: 0.8208\n",
            "Epoch 22/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0790 - accuracy: 0.9729 - val_loss: 0.7316 - val_accuracy: 0.8439\n",
            "Epoch 23/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0712 - accuracy: 0.9755 - val_loss: 0.8143 - val_accuracy: 0.8336\n",
            "Epoch 24/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.0676 - accuracy: 0.9772 - val_loss: 0.9198 - val_accuracy: 0.8059\n",
            "Epoch 25/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0744 - accuracy: 0.9753 - val_loss: 0.8370 - val_accuracy: 0.8266\n",
            "Epoch 26/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0614 - accuracy: 0.9799 - val_loss: 0.7562 - val_accuracy: 0.8419\n",
            "Epoch 27/30\n",
            "875/875 [==============================] - 28s 32ms/step - loss: 0.0681 - accuracy: 0.9756 - val_loss: 0.8522 - val_accuracy: 0.8280\n",
            "Epoch 28/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.0646 - accuracy: 0.9768 - val_loss: 0.7064 - val_accuracy: 0.8535\n",
            "Epoch 29/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.0636 - accuracy: 0.9785 - val_loss: 0.7306 - val_accuracy: 0.8504\n",
            "Epoch 30/30\n",
            "875/875 [==============================] - 29s 33ms/step - loss: 0.0618 - accuracy: 0.9788 - val_loss: 0.7620 - val_accuracy: 0.8513\n"
          ]
        }
      ]
    }
  ]
}