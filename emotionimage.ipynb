{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2887117,"sourceType":"datasetVersion","datasetId":1768625},{"sourceId":7582006,"sourceType":"datasetVersion","datasetId":4413646}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as functional\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom tqdm.auto import tqdm\nimport matplotlib\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T20:41:01.775002Z","iopub.execute_input":"2024-04-19T20:41:01.775380Z","iopub.status.idle":"2024-04-19T20:41:01.780524Z","shell.execute_reply.started":"2024-04-19T20:41:01.775354Z","shell.execute_reply":"2024-04-19T20:41:01.779651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.GaussianBlur(kernel_size=(5,9), sigma=(0.1, 5)),\n    transforms.RandomRotation(degrees=(30, 70)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.5, 0.5, 0.5],\n        std=[0.5, 0.5, 0.5]\n    )\n])\n\nvalid_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.5, 0.5, 0.5],\n        std=[0.5, 0.5, 0.5]\n    )\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T19:45:35.455439Z","iopub.execute_input":"2024-04-19T19:45:35.455874Z","iopub.status.idle":"2024-04-19T19:45:35.464528Z","shell.execute_reply.started":"2024-04-19T19:45:35.455843Z","shell.execute_reply":"2024-04-19T19:45:35.463461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(\n    root='/kaggle/input/rating-opencv-emotion-images/Images/train',\n    transform=train_transform\n)\n\nvalidation_dataset = datasets.ImageFolder(\n    root='/kaggle/input/rating-opencv-emotion-images/Images/validation',\n    transform=valid_transform\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:39:14.828880Z","iopub.execute_input":"2024-04-19T20:39:14.829471Z","iopub.status.idle":"2024-04-19T20:39:19.295997Z","shell.execute_reply.started":"2024-04-19T20:39:14.829432Z","shell.execute_reply":"2024-04-19T20:39:19.294980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n train_dataset, batch_size=batch_size, shuffle=True, \n num_workers=4, pin_memory=True\n)\n\nvalid_loader = DataLoader(\n    validation_dataset, batch_size=batch_size, shuffle=False,\n    num_workers=4, pin_memory=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:39:23.062597Z","iopub.execute_input":"2024-04-19T20:39:23.062952Z","iopub.status.idle":"2024-04-19T20:39:23.070508Z","shell.execute_reply.started":"2024-04-19T20:39:23.062925Z","shell.execute_reply":"2024-04-19T20:39:23.069353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:39:40.560806Z","iopub.execute_input":"2024-04-19T20:39:40.561463Z","iopub.status.idle":"2024-04-19T20:39:40.568250Z","shell.execute_reply.started":"2024-04-19T20:39:40.561422Z","shell.execute_reply":"2024-04-19T20:39:40.567322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageModel(nn.Module):\n    def __init__(self):\n        super(ImageModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 5)\n        self.conv2 = nn.Conv2d(32, 64, 5)\n        self.conv3 = nn.Conv2d(64, 128, 3)\n        self.conv4 = nn.Conv2d(128, 256, 5)\n        \n        self.fc1 = nn.Linear(256, 7)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n    def forward(self, x):\n        x = self.pool(functional.relu(self.conv1(x)))\n        x = self.pool(functional.relu(self.conv2(x)))\n        x = self.pool(functional.relu(self.conv3(x)))\n        x = self.pool(functional.relu(self.conv4(x)))\n        \n        bs, _, _, _ = x.shape\n        x = functional.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n        x = self.fc1(x)\n        return x\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:39:53.381527Z","iopub.execute_input":"2024-04-19T20:39:53.381922Z","iopub.status.idle":"2024-04-19T20:39:53.390369Z","shell.execute_reply.started":"2024-04-19T20:39:53.381895Z","shell.execute_reply":"2024-04-19T20:39:53.389582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3\nepochs = 30\n\ndevice = ('cuda' if torch.cuda.is_available() else 'cpu')\nimage_classifier = ImageModel().to(device)\noptimizer = optim.Adam(image_classifier.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ndevice, image_classifier","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:41:07.801065Z","iopub.execute_input":"2024-04-19T20:41:07.801410Z","iopub.status.idle":"2024-04-19T20:41:07.992196Z","shell.execute_reply.started":"2024-04-19T20:41:07.801383Z","shell.execute_reply":"2024-04-19T20:41:07.991297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_params = sum(p.numel() for p in image_classifier.parameters())\nprint(f\"{total_params:,} total parameters.\")\ntotal_trainable_params = sum(\n    p.numel() for p in image_classifier.parameters() if p.requires_grad)\nprint(f\"{total_trainable_params:,} training parameters.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T20:41:36.190415Z","iopub.execute_input":"2024-04-19T20:41:36.191355Z","iopub.status.idle":"2024-04-19T20:41:36.197323Z","shell.execute_reply.started":"2024-04-19T20:41:36.191319Z","shell.execute_reply":"2024-04-19T20:41:36.196394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(model, trainloader, optimizer, criterion):\n    model.train()\n    print('Training torch classifier')\n    training_run_loss = 0.0\n    training_run_correct = 0\n    counter = 0\n    for x, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n        counter += 1\n        image, labels = data\n        image = image.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        \n        outputs = model(image)\n        loss = criterion(outputs, labels)\n        training_run_loss += loss.item()\n        _, preds = torch.max(outputs.data, 1)\n        training_run_correct += (preds == labels).sum().item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    epoch_loss = training_run_loss / counter\n    epoch_acc = 100. * (training_run_correct / len(train_loader.dataset))\n    \ndef validate(model, valid_loader, criterion):\n    model.eval()\n    print('Validation')\n    valid_run_loss = 0.0\n    valid_run_correct = 0\n    counter = 0\n    \n    with torch.no_grad():\n        for i, data in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n            counter += 1\n            image, labels = data\n            image = image.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(image)\n            \n            loss = criterion(outputs, labels)\n            valid_run_loss += loss.item()\n            _, preds = torch.max(outputs.data, 1)\n            valid_run_correct += (preds == labels).sum().item()\n            \n    epoch_loss = valid_run_loss / counter\n    epoch_acc = 100. * (valid_run_correct / len(valid_loader.dataset))\n    return epoch_loss, epoch_acc\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n    \"\"\"\n    Function to save the loss and accuracy plots to disk.\n    \"\"\"\n    # accuracy plots\n    plt.figure(figsize=(10, 7))\n    plt.plot(\n        train_acc, color='green', linestyle='-', \n        label='train accuracy'\n    )\n    plt.plot(\n        valid_acc, color='blue', linestyle='-', \n        label='validataion accuracy'\n    )\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('outputs/accuracy.png')\n    \n    # loss plots\n    plt.figure(figsize=(10, 7))\n    plt.plot(\n        train_loss, color='orange', linestyle='-', \n        label='train loss'\n    )\n    plt.plot(\n        valid_loss, color='red', linestyle='-', \n        label='validation loss'\n    )\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('outputs/loss.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, valid_loss = [], []\ntrain_acc, valid_acc = [], []\n\nfor epoch in tqdm(range(epochs)):\n    print(f'[INFO]: Epoch {epoch+1} of {epochs}')\n    train_epoch_loss, train_epoch_acc = training(image_classifier, train_loader, optimizer, criterion)\n    valid_epoch_loss, valid_epoch_acc = validate(image_classifier, valid_loader, criterion)\n    \n    train_loss.append(train_epoch_loss)\n    valid_loss.append(valid_epoch_loss)\n    train_acc.append(train_epoch_acc)\n    valid_acc.append(valid_epoch_acc)\n    \n    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f * 100}\")\n    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f * 100}\")\n    print('-'*50)\n    time.sleep(5)\n    \nsave_model(epochs, image_classifier, optimizer, criterion)\nsave_plots(train_acc, valid_acc, train_loss, valid_loss)\nprint('Training Complete')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}