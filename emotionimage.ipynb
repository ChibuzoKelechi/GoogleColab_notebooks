{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35c4bf2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:01.693764Z",
     "iopub.status.busy": "2024-04-19T20:47:01.693361Z",
     "iopub.status.idle": "2024-04-19T20:47:08.886697Z",
     "shell.execute_reply": "2024-04-19T20:47:08.885869Z"
    },
    "papermill": {
     "duration": 7.201034,
     "end_time": "2024-04-19T20:47:08.889059",
     "exception": false,
     "start_time": "2024-04-19T20:47:01.688025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as functional\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b3edf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:08.897876Z",
     "iopub.status.busy": "2024-04-19T20:47:08.897069Z",
     "iopub.status.idle": "2024-04-19T20:47:08.904674Z",
     "shell.execute_reply": "2024-04-19T20:47:08.903829Z"
    },
    "papermill": {
     "duration": 0.013677,
     "end_time": "2024-04-19T20:47:08.906541",
     "exception": false,
     "start_time": "2024-04-19T20:47:08.892864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(5,9), sigma=(0.1, 5)),\n",
    "    transforms.RandomRotation(degrees=(30, 70)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5787fff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:08.914482Z",
     "iopub.status.busy": "2024-04-19T20:47:08.913726Z",
     "iopub.status.idle": "2024-04-19T20:47:20.494826Z",
     "shell.execute_reply": "2024-04-19T20:47:20.494040Z"
    },
    "papermill": {
     "duration": 11.587407,
     "end_time": "2024-04-19T20:47:20.497162",
     "exception": false,
     "start_time": "2024-04-19T20:47:08.909755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    root='/kaggle/input/rating-opencv-emotion-images/Images/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "validation_dataset = datasets.ImageFolder(\n",
    "    root='/kaggle/input/rating-opencv-emotion-images/Images/validation',\n",
    "    transform=valid_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704205b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:20.505160Z",
     "iopub.status.busy": "2024-04-19T20:47:20.504878Z",
     "iopub.status.idle": "2024-04-19T20:47:20.509904Z",
     "shell.execute_reply": "2024-04-19T20:47:20.509125Z"
    },
    "papermill": {
     "duration": 0.011007,
     "end_time": "2024-04-19T20:47:20.511714",
     "exception": false,
     "start_time": "2024-04-19T20:47:20.500707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    " train_dataset, batch_size=batch_size, shuffle=True, \n",
    " num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    validation_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4473e407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:20.519475Z",
     "iopub.status.busy": "2024-04-19T20:47:20.519201Z",
     "iopub.status.idle": "2024-04-19T20:47:20.525821Z",
     "shell.execute_reply": "2024-04-19T20:47:20.524930Z"
    },
    "papermill": {
     "duration": 0.01286,
     "end_time": "2024-04-19T20:47:20.527881",
     "exception": false,
     "start_time": "2024-04-19T20:47:20.515021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 28709\n",
       "    Root location: /kaggle/input/rating-opencv-emotion-images/Images/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               RandomVerticalFlip(p=0.5)\n",
       "               GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))\n",
       "               RandomRotation(degrees=[30.0, 70.0], interpolation=nearest, expand=False, fill=0)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bc238a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:20.536074Z",
     "iopub.status.busy": "2024-04-19T20:47:20.535805Z",
     "iopub.status.idle": "2024-04-19T20:47:20.544072Z",
     "shell.execute_reply": "2024-04-19T20:47:20.543313Z"
    },
    "papermill": {
     "duration": 0.014383,
     "end_time": "2024-04-19T20:47:20.545963",
     "exception": false,
     "start_time": "2024-04-19T20:47:20.531580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 7)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(functional.relu(self.conv1(x)))\n",
    "        x = self.pool(functional.relu(self.conv2(x)))\n",
    "        x = self.pool(functional.relu(self.conv3(x)))\n",
    "        x = self.pool(functional.relu(self.conv4(x)))\n",
    "        \n",
    "        bs, _, _, _ = x.shape\n",
    "        x = functional.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d979366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:20.553928Z",
     "iopub.status.busy": "2024-04-19T20:47:20.553283Z",
     "iopub.status.idle": "2024-04-19T20:47:20.811132Z",
     "shell.execute_reply": "2024-04-19T20:47:20.810225Z"
    },
    "papermill": {
     "duration": 0.26388,
     "end_time": "2024-04-19T20:47:20.813115",
     "exception": false,
     "start_time": "2024-04-19T20:47:20.549235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda',\n",
       " ImageModel(\n",
       "   (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (conv4): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (fc1): Linear(in_features=256, out_features=7, bias=True)\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 30\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_classifier = ImageModel().to(device)\n",
    "optimizer = optim.Adam(image_classifier.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device, image_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f247fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:20.821674Z",
     "iopub.status.busy": "2024-04-19T20:47:20.821164Z",
     "iopub.status.idle": "2024-04-19T20:47:20.827479Z",
     "shell.execute_reply": "2024-04-19T20:47:20.826224Z"
    },
    "papermill": {
     "duration": 0.012717,
     "end_time": "2024-04-19T20:47:20.829549",
     "exception": false,
     "start_time": "2024-04-19T20:47:20.816832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948,807 total parameters.\n",
      "948,807 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in image_classifier.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in image_classifier.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf80d633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T20:47:20.839133Z",
     "iopub.status.busy": "2024-04-19T20:47:20.838684Z",
     "iopub.status.idle": "2024-04-19T20:47:20.843163Z",
     "shell.execute_reply": "2024-04-19T20:47:20.842313Z"
    },
    "papermill": {
     "duration": 0.011761,
     "end_time": "2024-04-19T20:47:20.845092",
     "exception": false,
     "start_time": "2024-04-19T20:47:20.833331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training torch classifier')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1768625,
     "sourceId": 2887117,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4413646,
     "sourceId": 7582006,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.145817,
   "end_time": "2024-04-19T20:47:23.134582",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-19T20:46:58.988765",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
